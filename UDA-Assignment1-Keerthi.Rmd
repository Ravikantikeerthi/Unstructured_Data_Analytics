---
title: "UDA-Assignment1-Keerthi"
output: 

html_document: default
pdf_document: default
---
```{r}
#PROBLEM STATEMENT

#1. Scrape tweets for the hashtag #datascience and do the following
#a. Hour wise or minute wise (depending upon the scrapped tweets) number of tweets - draw a line chart
#b. Top ten users with more number of tweets
#c. Create a new column in the data itself, to identity total number of hashtags in each tweet
#d. Identity those users who have used #datascience as well as #machinelearning. Plot a bar chart top 10 users based on their count
#2. Scrape tweets from @narendramodi and do the following:
#a. Create a word cloud using the hashtags used in his tweets. (If you are not able to scrape
#more tweets, please use the data set which was shared already)
#b. For each quarter identify top 5 hashtags based on frequency. Represent them using bar
#charts (Tip: use facets)

```

```{r}
rm(list=ls())

setwd("C:/Users/Kikku/Google Drive/1 Data Science/11 unstructured data analytics/Assignments")

#Question 1. Scrape tweets for the hashtag #datascience and do the following

library(twitteR)
library(stringr)
library(stringi)
library(tm)
library(wordcloud)
library(dplyr)
library(ggplot2)
library(ggthemes)



#api_key = "9EWT4rx9Vkj69vLc9rq1"
#api_secret = "7wnvAKFSchn15IFXxDPNO7J6OCgk19k806VYpAgrz0XO"
#token = "220030109-PhiD3scJV9ueTfZismN8XobXL6zZkcKh"
#token_secret = "iZvm4sQbw9T82Zd9V35l4zKnoIthkfuj3l18js"

#setup_twitter_oauth(api_key, api_secret, token, token_secret)
#datascience <- searchTwitter("#datascience", n = 2000)

#Converting scraped tweets into data frame
#df.datascience = twListToDF(datascience)
#write.csv(df.datascience, "datascience_hashtags.csv")

df.datascience = read.csv("datascience_hashtags.csv")
head(df.datascience)
```

```{r}
#----------------------------------------------------------------------------------------------
# 1a. Hour wise or minute wise (depending upon the scrapped tweets) number of tweets-draw a
# line chart
#----------------------------------------------------------------------------------------------

#convert the timestamp column in to date time object
df.datascience$created = as.POSIXct(df.datascience$created)

## Extract hour and minutes from date time
df.datascience$min = format(df.datascience$created, "%M")

## Minute wise Tweets
tweets_min = df.datascience %>% group_by(min) %>% summarise(count=n())
tweets_min
## Line Chart - Minute wise tweets

minutewise_linechart <- ggplot(tweets_min, aes(x=min, y=count, group=1)) + geom_line() + geom_point() + xlab("Minutes (GMT)") + ylab("# Tweets")

minutewise_linechart

```

```{r}

#--------------------------------------------------------------------------------------
# 1b.Top ten users with more number of tweets
#--------------------------------------------------------------------------------------

length(df.datascience$screenName)
length(unique(df.datascience$screenName))

## Grouping the data based on user and calculating the count for user tweets
tweets_user <- df.datascience %>% group_by(screenName) %>% summarise(count=n())
tweets_user <- tweets_user %>% arrange(-count)
class(tweets_user)
#View(tweets_user)
top_10 <- head(tweets_user, 10)
top_10
```

```{r}

#-----------------------------------------------------------------------------------------------
# 1c. Create a new column in the data itself, to identity total number of hashtags in each tweet
#-----------------------------------------------------------------------------------------------

df.datascience$hashtag_count <- str_count(df.datascience$text, "#")
#View(df.datascience)


```

```{r}

#-------------------------------------------------------------------------------------------
# 1d. Identity those users who have used #datascience as well as #machinelearning. Plot a bar
# chart top 10 users based on their count
#-------------------------------------------------------------------------------------------

#Filtering tweets containing both #datascience and #machinelearning
ML_DS= subset(df.datascience, grepl("#machinelearning", df.datascience$text))
dim(ML_DS)

# Getting count on screen name
count_screenName=count(ML_DS,screenName)

#Sorting the frequency of users and pulling out the top 10 users
top_10 = head(count_screenName[order(count_screenName$n,decreasing=TRUE),c(1,2)],10)

#Plotting a bar plot for top 10 users
top_10$screenName <- factor(top_10$screenName, levels = top_10$screenName[order(-top_10$n)])

ggplot(data=top_10, aes(y=n, x=screenName)) + geom_bar(stat="identity", fill="firebrick") + 
  theme_tufte() + labs(title="Top 10 users of both #datascience & #machinelearning",
                       x="User ScreenName", y="# of Tweets") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```


```{r}
#----------------------------------------------------------------------------------
# Assignment 1 - Question 2: Scrape tweets from @narendramodi and do the following:
#----------------------------------------------------------------------------------

df.modi <- read.csv("C:/Users/Kikku/Google Drive/1 Data Science/11 unstructured data analytics/Lab/narendramodi_tweets.csv")

head(df.modi)

#----------------------------------------------------------------------------------------------
# 2a. Create a word cloud using the hashtags used in his tweets. (If you are not able to scrape
# more tweets, please use the data set which was shared already)
#----------------------------------------------------------------------------------------------

# Step # 1: get the hashtags
modi_hashtags = str_extract_all(df.modi$text, "#\\w+")
# Step # 2: put tags in vector
modi_hashtags = unlist(modi_hashtags)
# Step # 3: calculate hashtag frequencies
modi_hashtags_freq = table(modi_hashtags)


# Step # 4: Let's plot wordclouds for each user
wordcloud(names(modi_hashtags_freq),
          modi_hashtags_freq, 
          max.words = 50,
          scale=c(4,.5),
          rot.per=.3,
          random.order=FALSE, 
          colors="#1B9E77")
        title("\n\nHashtags in Narendra Modi Tweets",
      cex.main=1, col.main="gray50")


```

```{r}
#------------------------------------------------------------------------------------------------------------------
# 2b. For each quarter identify top 5 hashtags based on frequency. Represent them using bar charts (Tip: use    facets)
#------------------------------------------------------------------------------------------------------------------


df.modi$quarter = paste(format(as.Date(df.modi$created_at), "%Y"), quarters(as.Date(df.modi$created_at)))
#View(df.modi)

df.modi_2016Q1 = df.modi[df.modi$quarter == "2016 Q1",]
df.modi_2016Q2 = df.modi[df.modi$quarter == "2016 Q2",]
df.modi_2016Q3 = df.modi[df.modi$quarter == "2016 Q3",]
df.modi_2016Q4 = df.modi[df.modi$quarter == "2016 Q4",]
df.modi_2017Q1 = df.modi[df.modi$quarter == "2017 Q1",]

# Extracting hashtags- Quarter wise and keeping the same in a vector format
modi_hashtags_2016Q1 = unlist(str_extract_all(df.modi_2016Q1$text, "#\\w+"))
modi_hashtags_2016Q2 = unlist(str_extract_all(df.modi_2016Q2$text, "#\\w+"))
modi_hashtags_2016Q3 = unlist(str_extract_all(df.modi_2016Q3$text, "#\\w+"))
modi_hashtags_2016Q4 = unlist(str_extract_all(df.modi_2016Q4$text, "#\\w+"))
modi_hashtags_2017Q1 = unlist(str_extract_all(df.modi_2017Q1$text, "#\\w+"))

#Calculating the hashtags frequncies - quarter wise
modi_hashtags_2016Q1_freq = head(sort(table(modi_hashtags_2016Q1), decreasing = TRUE),5)
modi_hashtags_2016Q2_freq = head(sort(table(modi_hashtags_2016Q2), decreasing = TRUE),5)
modi_hashtags_2016Q3_freq = head(sort(table(modi_hashtags_2016Q3), decreasing = TRUE),5)
modi_hashtags_2016Q4_freq = head(sort(table(modi_hashtags_2016Q4), decreasing = TRUE),5)
modi_hashtags_2017Q1_freq = head(sort(table(modi_hashtags_2017Q1), decreasing = TRUE),5)

#cONVERTING TABLE TO a data fra,e
modi_hashtags_2016Q1_freq = as.data.frame(modi_hashtags_2016Q1_freq)
modi_hashtags_2016Q1_freq$qtr = ("2016-Q1")
colnames(modi_hashtags_2016Q1_freq)[1] = "modi_hashtags"

modi_hashtags_2016Q2_freq = as.data.frame(modi_hashtags_2016Q2_freq)
modi_hashtags_2016Q2_freq$qtr = ("2016-Q2")
colnames(modi_hashtags_2016Q2_freq)[1] = "modi_hashtags"

modi_hashtags_2016Q3_freq = as.data.frame(modi_hashtags_2016Q3_freq)
modi_hashtags_2016Q3_freq$qtr = ("2016-Q3")
colnames(modi_hashtags_2016Q3_freq)[1] = "modi_hashtags"

modi_hashtags_2016Q4_freq = as.data.frame(modi_hashtags_2016Q4_freq)
modi_hashtags_2016Q4_freq$qtr = ("2016-Q4")
colnames(modi_hashtags_2016Q4_freq)[1] = "modi_hashtags"

modi_hashtags_2017Q1_freq = as.data.frame(modi_hashtags_2017Q1_freq)
modi_hashtags_2017Q1_freq$qtr = ("2017-Q1")
colnames(modi_hashtags_2017Q1_freq)[1] = "modi_hashtags"

# Appending the data of all the 5 quarters

modi_hashtags_quarter = rbind(modi_hashtags_2016Q1_freq, modi_hashtags_2016Q2_freq,
                              modi_hashtags_2016Q3_freq,modi_hashtags_2016Q4_freq,
                              modi_hashtags_2017Q1_freq)

# Plotting a Bar Chart (using facets) - representing quarter wise #hashtags data
str(modi_hashtags_quarter)

ggplot(modi_hashtags_quarter, aes(x=reorder(modi_hashtags, Freq),y=Freq)) + geom_bar(stat = "identity",position="dodge", fill="firebrick") +
  facet_wrap( ~ qtr, scales= "free") + theme_grey(base_size = 8) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))


```

